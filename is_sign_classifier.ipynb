{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a32ab3d",
   "metadata": {
    "id": "5a32ab3d"
   },
   "source": [
    "This is a Neural-Network, that determines if the image (data) is a sign, or not. (2 labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "7de4692a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 315
    },
    "executionInfo": {
     "elapsed": 11997,
     "status": "error",
     "timestamp": 1768423910987,
     "user": {
      "displayName": "Göblyös Bence",
      "userId": "08664305870357546122"
     },
     "user_tz": -60
    },
    "id": "7de4692a",
    "outputId": "afd61e52-db80-4c49-fd45-7cff60c7967a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images...\n",
      "  Finished no: Loaded 83 images.\n",
      "  Finished yes: Loaded 288 images.\n",
      "\n",
      "Total Dataset: 371 images loaded.\n",
      "Feature vector size: 1024 (32x32x3 pixels)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training..\n",
      "\n",
      "--- Evaluation ---\n",
      "Model Accuracy: 97.33%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          no       1.00      0.91      0.95        23\n",
      "         yes       0.96      1.00      0.98        52\n",
      "\n",
      "    accuracy                           0.97        75\n",
      "   macro avg       0.98      0.96      0.97        75\n",
      "weighted avg       0.97      0.97      0.97        75\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Dictionary - arrow types and labels\n",
    "folders = {\n",
    "    \"no\": 0,\n",
    "    \"yes\": 1\n",
    "}\n",
    "\n",
    "# The parent folder in drive\n",
    "base_folder = \"data/is_sign/train\"\n",
    "\n",
    "\n",
    "# resize img\n",
    "IMG_SIZE = (32, 32)\n",
    "\n",
    "\n",
    "X_data = [] #  pixel values\n",
    "y_data = [] #  labels\n",
    "\n",
    "print(\"Loading images...\")\n",
    "\n",
    "for folder_name, label in folders.items():\n",
    "\n",
    "    # File path in drive\n",
    "    folder_path = os.path.join(base_folder, folder_name)\n",
    "\n",
    "    # IF NO folder, SKIP\n",
    "    if not os.path.exists(folder_path):\n",
    "        print(f\"Warning: Folder not found: {folder_path}\")\n",
    "        continue\n",
    "\n",
    "    # Get a list of ALL files in this folder\n",
    "    files = os.listdir(folder_path)\n",
    "\n",
    "    count = 0\n",
    "    for filename in files:\n",
    "        # if PNG file\n",
    "        if filename.lower().endswith(\".png\"):\n",
    "\n",
    "            #  full path\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "\n",
    "            try:\n",
    "                img = cv2.imread(file_path)\n",
    "\n",
    "                if img is not None:\n",
    "                    # Resize, Flatten, Normalize\n",
    "                    img = cv2.resize(img[:,:,0], IMG_SIZE)\n",
    "                    flat_img = img.flatten()\n",
    "                    norm_img = flat_img / 255.0\n",
    "\n",
    "                    X_data.append(norm_img)\n",
    "                    y_data.append(label)\n",
    "                    count += 1\n",
    "                else:\n",
    "                    print(f\"Warning: Could not open {filename}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading {filename}: {e}\")\n",
    "\n",
    "    print(f\"  Finished {folder_name}: Loaded {count} images.\")\n",
    "\n",
    "# Convert lists to np\n",
    "X = np.array(X_data)\n",
    "y = np.array(y_data)\n",
    "\n",
    "\n",
    "if len(X) == 0:\n",
    "    print(\"Error: No images found. Check folder structure and paths.\")\n",
    "    exit()\n",
    "\n",
    "print(f\"\\nTotal Dataset: {len(X)} images loaded.\")\n",
    "print(f\"Feature vector size: {X.shape[1]} (32x32x3 pixels)\")\n",
    "\n",
    "#plot an img\n",
    "image_index = 0\n",
    "flat_image = X[image_index]  #  1D array of flattened image\n",
    "\n",
    "# Reshape it back to (Height, Width, Channels)\n",
    "# use IMG_SIZE (32, 32) and 3 channels\n",
    "restored_image = flat_image.reshape(32, 32)\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.imshow(restored_image)\n",
    "plt.title(f\"Label: {y[image_index]}\")\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"\\nTraining..\")\n",
    "\n",
    "#  Multi-Layer Perceptron Classifier\n",
    "# hidden_layer_sizes=(100, 50): Two layers of \"neurons\"\n",
    "\n",
    "clf = MLPClassifier(\n",
    "    hidden_layer_sizes=(100, 50),\n",
    "    max_iter=500,\n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    random_state=1\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n--- Evaluation ---\")\n",
    "predictions = clf.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "acc = accuracy_score(y_test, predictions)\n",
    "print(f\"Model Accuracy: {acc*100:.2f}%\")\n",
    "\n",
    "# detailed report\n",
    "target_names = list(folders.keys())\n",
    "print(classification_report(y_test, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "t-0jBKj4Rvs6",
   "metadata": {
    "id": "t-0jBKj4Rvs6"
   },
   "outputs": [],
   "source": [
    "M1, M2, M3 = clf.coefs_\n",
    "model_dir = \"models/is_sign\"\n",
    "np.savetxt(f\"{model_dir}/M1.csv\", M1, delimiter=\",\")\n",
    "np.savetxt(f\"{model_dir}/M2.csv\", M2, delimiter=\",\")\n",
    "np.savetxt(f\"{model_dir}/M3.csv\", M3, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "95bc8794-fde2-4679-b7e1-8471b444e942",
   "metadata": {},
   "outputs": [],
   "source": [
    "b1, b2, b3 = clf.intercepts_\n",
    "np.savetxt(f\"{model_dir}/b1.csv\", b1, delimiter=\",\")\n",
    "np.savetxt(f\"{model_dir}/b2.csv\", b2, delimiter=\",\")\n",
    "np.savetxt(f\"{model_dir}/b3.csv\", b3, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "933af2d3-bbaf-49f8-9773-4263a67c18a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f3831002-0080-4325-816b-7104a535d27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return np.maximum(x, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "fa89356d-a079-4edd-94f3-4760ab7602f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.23702363e-02,  1.34412224e-07, -4.35701884e-02, ...,\n",
       "        -1.03873203e-02, -4.73786313e-02, -6.15675072e-08],\n",
       "       [-2.02291145e-02,  3.71658678e-10,  3.34719134e-02, ...,\n",
       "        -1.05967358e-02,  6.01712473e-03,  2.97009719e-05],\n",
       "       [ 3.39909891e-02, -7.36152159e-09,  3.60518690e-02, ...,\n",
       "        -1.11516283e-02,  3.78540045e-02, -3.63952526e-06],\n",
       "       ...,\n",
       "       [ 2.12567369e-02, -1.48938279e-05, -8.83551624e-03, ...,\n",
       "        -1.21751188e-02, -4.13417140e-02, -6.89590296e-08],\n",
       "       [ 3.27733701e-02, -4.76971274e-10,  3.61547814e-02, ...,\n",
       "        -1.05078439e-02,  2.41677471e-02,  7.88533830e-08],\n",
       "       [-1.84150772e-02,  1.75042918e-06,  3.34791500e-02, ...,\n",
       "        -1.14724247e-02,  2.33490874e-02,  8.39530630e-08]],\n",
       "      shape=(3072, 100))"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.loadtxt(f\"{model_dir}/M1.csv\", delimiter = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f090a37f-b5eb-47d3-8708-ff56884b80ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def homebrewMLP(X):\n",
    "    state = relu(np.matmul(X, M1) + b1)\n",
    "    state = relu(np.matmul(state, M2) + b2)\n",
    "    state = np.matmul(state, M3) + b3\n",
    "    return state[0] > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7bfea360-f78e-4366-8db6-f9c6eaf2eca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if homebrewMLP(X[10]):\n",
    "    print(\"Sign!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19785145-20d2-4c0b-a103-2db3181f6e41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
